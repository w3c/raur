<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta charset="utf-8">
<meta name="generator" content="ReSpec 32.1.0">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<style>
.issue-label{text-transform:initial}
.warning>p:first-child{margin-top:0}
.warning{padding:.5em;border-left-width:.5em;border-left-style:solid}
span.warning{padding:.1em .5em .15em}
.issue.closed span.issue-number{text-decoration:line-through}
.warning{border-color:#f11;border-width:.2em;border-style:solid;background:#fbe9e9}
.warning-title:before{content:"⚠";font-size:1.3em;float:left;padding-right:.3em;margin-top:-.3em}
li.task-list-item{list-style:none}
input.task-list-item-checkbox{margin:0 .35em .25em -1.6em;vertical-align:middle}
.issue a.respec-gh-label{padding:5px;margin:0 2px 0 2px;font-size:10px;text-transform:none;text-decoration:none;font-weight:700;border-radius:4px;position:relative;bottom:2px;border:none;display:inline-block}
</style>
<style>
dfn{cursor:pointer}
.dfn-panel{position:absolute;z-index:35;min-width:300px;max-width:500px;padding:.5em .75em;margin-top:.6em;font:small Helvetica Neue,sans-serif,Droid Sans Fallback;background:#fff;color:#000;box-shadow:0 1em 3em -.4em rgba(0,0,0,.3),0 0 1px 1px rgba(0,0,0,.05);border-radius:2px}
.dfn-panel:not(.docked)>.caret{position:absolute;top:-9px}
.dfn-panel:not(.docked)>.caret::after,.dfn-panel:not(.docked)>.caret::before{content:"";position:absolute;border:10px solid transparent;border-top:0;border-bottom:10px solid #fff;top:0}
.dfn-panel:not(.docked)>.caret::before{border-bottom:9px solid #a2a9b1}
.dfn-panel *{margin:0}
.dfn-panel b{display:block;color:#000;margin-top:.25em}
.dfn-panel ul a[href]{color:#333}
.dfn-panel>div{display:flex}
.dfn-panel a.self-link{font-weight:700;margin-right:auto}
.dfn-panel .marker{padding:.1em;margin-left:.5em;border-radius:.2em;text-align:center;white-space:nowrap;font-size:90%;color:#040b1c}
.dfn-panel .marker.dfn-exported{background:#d1edfd;box-shadow:0 0 0 .125em #1ca5f940}
.dfn-panel .marker.idl-block{background:#8ccbf2;box-shadow:0 0 0 .125em #0670b161}
.dfn-panel a:not(:hover){text-decoration:none!important;border-bottom:none!important}
.dfn-panel a[href]:hover{border-bottom-width:1px}
.dfn-panel ul{padding:0}
.dfn-panel li{margin-left:1em}
.dfn-panel.docked{position:fixed;left:.5em;top:unset;bottom:2em;margin:0 auto;max-width:calc(100vw - .75em * 2 - .5em - .2em * 2);max-height:30vh;overflow:auto}
</style>
		
		
<title>RTC Accessibility User Requirements</title>
		
		
		
		
	
<style id="respec-mainstyle">
@keyframes pop{
0%{transform:scale(1,1)}
25%{transform:scale(1.25,1.25);opacity:.75}
100%{transform:scale(1,1)}
}
:is(h1,h2,h3,h4,h5,h6,a) abbr{border:none}
dfn{font-weight:700}
a.internalDFN{color:inherit;border-bottom:1px solid #99c;text-decoration:none}
a.externalDFN{color:inherit;border-bottom:1px dotted #ccc;text-decoration:none}
a.bibref{text-decoration:none}
.respec-offending-element:target{animation:pop .25s ease-in-out 0s 1}
.respec-offending-element,a[href].respec-offending-element{text-decoration:red wavy underline}
@supports not (text-decoration:red wavy underline){
.respec-offending-element:not(pre){display:inline-block}
.respec-offending-element{background:url(data:image/gif;base64,R0lGODdhBAADAPEAANv///8AAP///wAAACwAAAAABAADAEACBZQjmIAFADs=) bottom repeat-x}
}
#references :target{background:#eaf3ff;animation:pop .4s ease-in-out 0s 1}
cite .bibref{font-style:normal}
code{color:#c63501}
th code{color:inherit}
a[href].orcid{padding-left:4px;padding-right:4px}
a[href].orcid>svg{margin-bottom:-2px}
.toc a,.tof a{text-decoration:none}
a .figno,a .secno{color:#000}
ol.tof,ul.tof{list-style:none outside none}
.caption{margin-top:.5em;font-style:italic}
table.simple{border-spacing:0;border-collapse:collapse;border-bottom:3px solid #005a9c}
.simple th{background:#005a9c;color:#fff;padding:3px 5px;text-align:left}
.simple th a{color:#fff;padding:3px 5px;text-align:left}
.simple th[scope=row]{background:inherit;color:inherit;border-top:1px solid #ddd}
.simple td{padding:3px 10px;border-top:1px solid #ddd}
.simple tr:nth-child(even){background:#f0f6ff}
.section dd>p:first-child{margin-top:0}
.section dd>p:last-child{margin-bottom:0}
.section dd{margin-bottom:1em}
.section dl.attrs dd,.section dl.eldef dd{margin-bottom:0}
#issue-summary>ul{column-count:2}
#issue-summary li{list-style:none;display:inline-block}
details.respec-tests-details{margin-left:1em;display:inline-block;vertical-align:top}
details.respec-tests-details>*{padding-right:2em}
details.respec-tests-details[open]{z-index:999999;position:absolute;border:thin solid #cad3e2;border-radius:.3em;background-color:#fff;padding-bottom:.5em}
details.respec-tests-details[open]>summary{border-bottom:thin solid #cad3e2;padding-left:1em;margin-bottom:1em;line-height:2em}
details.respec-tests-details>ul{width:100%;margin-top:-.3em}
details.respec-tests-details>li{padding-left:1em}
.self-link:hover{opacity:1;text-decoration:none;background-color:transparent}
aside.example .marker>a.self-link{color:inherit}
.header-wrapper{display:flex;align-items:baseline}
:is(h2,h3,h4,h5,h6):not(#toc>h2,#abstract>h2,#sotd>h2,.head>h2){position:relative;left:-.5em}
:is(h2,h3,h4,h5,h6):not(#toch2)+a.self-link{color:inherit;order:-1;position:relative;left:-1.1em;font-size:1rem;opacity:.5}
:is(h2,h3,h4,h5,h6)+a.self-link::before{content:"§";text-decoration:none;color:var(--heading-text)}
:is(h2,h3)+a.self-link{top:-.2em}
:is(h4,h5,h6)+a.self-link::before{color:#000}
@media (max-width:767px){
dd{margin-left:0}
}
@media print{
.removeOnSave{display:none}
}
</style>
<meta name="description" content="This document outlines various accessibility related user needs, requirements and scenarios for real-time communication (RTC). These user needs should drive accessibility requirements in various related specifications and the overall architecture that enables it. It first introduces a definition of RTC as used throughout the document and outlines how RTC accessibility can support the needs of people with disabilities. It defines the term user needs as used throughout the document and then goes on to list a range of these user needs and their related requirements. Following that some quality related scenarios are outlined and finally a data table that maps the user needs contained in this document to related use case requirements found in other technical specifications.">
<style>
var{position:relative;cursor:pointer}
var[data-type]::after,var[data-type]::before{position:absolute;left:50%;top:-6px;opacity:0;transition:opacity .4s;pointer-events:none}
var[data-type]::before{content:"";transform:translateX(-50%);border-width:4px 6px 0 6px;border-style:solid;border-color:transparent;border-top-color:#000}
var[data-type]::after{content:attr(data-type);transform:translateX(-50%) translateY(-100%);background:#000;text-align:center;font-family:"Dank Mono","Fira Code",monospace;font-style:normal;padding:6px;border-radius:3px;color:#daca88;text-indent:0;font-weight:400}
var[data-type]:hover::after,var[data-type]:hover::before{opacity:1}
</style>
<script id="initialUserConfig" type="application/json">{
  "trace": true,
  "useExperimentalStyles": true,
  "doRDFa": "1.1",
  "includePermalinks": true,
  "permalinkEdge": true,
  "permalinkHide": false,
  "noRecTrack": true,
  "tocIntroductory": true,
  "specStatus": "ED",
  "diffTool": "http://www.aptest.com/standards/htmldiff/htmldiff.pl",
  "shortName": "raur",
  "copyrightStart": "2020",
  "license": "w3c-software-doc",
  "edDraftURI": "https://w3c.github.io/apa/raur/",
  "editors": [
    {
      "name": "Joshue O'Connor",
      "url": "https://www.w3.org/People#joconnor",
      "company": "W3C",
      "companyURI": "https://www.w3.org/",
      "w3cid": 41218
    },
    {
      "name": "Janina Sajka",
      "url": "https://rednote.net/",
      "w3cid": 33688
    },
    {
      "name": "Jason White",
      "company": "Educational Testing Service",
      "mailto": "jjwhite@ets.org",
      "companyURI": "https://www.ets.org/",
      "w3cid": 74028,
      "url": "mailto:jjwhite@ets.org"
    },
    {
      "name": "Michael Cooper",
      "url": "https://www.w3.org/People/cooper/",
      "company": "W3C",
      "companyURI": "https://www.w3.org/",
      "w3cid": 34017
    }
  ],
  "group": "apa",
  "github": "w3c/apa",
  "maxTocLevel": 4,
  "publishISODate": "2022-03-30T00:00:00.000Z",
  "generatedSubtitle": "W3C Editor's Draft 30 March 2022"
}</script>
<link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2021/W3C-ED"></head>
	<body class="h-entry informative"><div class="head">
    <p class="logos"><a class="logo" href="https://www.w3.org/"><img crossorigin="" alt="W3C" height="48" src="https://www.w3.org/StyleSheets/TR/2021/logos/W3C" width="72">
  </a></p>
    <h1 id="title" class="title">RTC Accessibility User Requirements</h1> 
    <p id="w3c-state"><a href="https://www.w3.org/standards/types#ED">W3C Editor's Draft</a> <time class="dt-published" datetime="2022-03-30">30 March 2022</time></p>
    <details open="">
      <summary>More details about this document</summary>
      <dl>
        <dt>This version:</dt><dd>
                <a class="u-url" href="https://w3c.github.io/apa/raur/">https://w3c.github.io/apa/raur/</a>
              </dd>
        <dt>Latest published version:</dt><dd>
                <a href="https://www.w3.org/TR/raur/">https://www.w3.org/TR/raur/</a>
              </dd>
        <dt>Latest editor's draft:</dt><dd><a href="https://w3c.github.io/apa/raur/">https://w3c.github.io/apa/raur/</a></dd>
        <dt>History:</dt><dd>
                    <a href="https://www.w3.org/standards/history/raur">https://www.w3.org/standards/history/raur</a>
                  </dd><dd>
                    <a href="https://github.com/w3c/apa/commits/">Commit history</a>
                  </dd>
        
        
        
        
        
        <dt>Editors:</dt><dd class="editor p-author h-card vcard" data-editor-id="41218">
    <a class="u-url url p-name fn" href="https://www.w3.org/People#joconnor">Joshue O'Connor</a> (<span class="p-org org h-org">W3C</span>)
  </dd><dd class="editor p-author h-card vcard" data-editor-id="33688">
    <a class="u-url url p-name fn" href="https://rednote.net/">Janina Sajka</a>
  </dd><dd class="editor p-author h-card vcard" data-editor-id="74028">
    <a class="ed_mailto u-email email p-name" href="mailto:jjwhite@ets.org">Jason White</a> (<span class="p-org org h-org">Educational Testing Service</span>)
  </dd><dd class="editor p-author h-card vcard" data-editor-id="34017">
    <a class="u-url url p-name fn" href="https://www.w3.org/People/cooper/">Michael Cooper</a> (<span class="p-org org h-org">W3C</span>)
  </dd>
        
        
        <dt>Feedback:</dt><dd>
        <a href="https://github.com/w3c/apa/">GitHub w3c/apa</a>
        (<a href="https://github.com/w3c/apa/pulls/">pull requests</a>,
        <a href="https://github.com/w3c/apa/issues/new/choose">new issue</a>,
        <a href="https://github.com/w3c/apa/issues/">open issues</a>)
      </dd>
        
        
      </dl>
    </details>
    
    
    <p class="copyright">
    <a href="https://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a>
    ©
    2020-2022
    
    <a href="https://www.w3.org/"><abbr title="World Wide Web Consortium">W3C</abbr></a><sup>®</sup> (<a href="https://www.csail.mit.edu/"><abbr title="Massachusetts Institute of Technology">MIT</abbr></a>,
    <a href="https://www.ercim.eu/"><abbr title="European Research Consortium for Informatics and Mathematics">ERCIM</abbr></a>, <a href="https://www.keio.ac.jp/">Keio</a>,
    <a href="https://ev.buaa.edu.cn/">Beihang</a>). W3C
    <a href="https://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>,
    <a href="https://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a> and
    <a rel="license" href="https://www.w3.org/Consortium/Legal/2015/copyright-software-and-document" title="W3C Software and Document Notice and License">permissive document license</a> rules apply.
  </p>
    <hr title="Separator for header">
  </div>
		<section id="abstract" class="introductory"><h2>Abstract</h2>
			
<p>This document outlines various accessibility related user needs, requirements and scenarios for real-time communication (<abbr title="real-time communication">RTC</abbr>). These user needs should drive accessibility requirements in various related specifications and the overall architecture that enables it. It first introduces a definition of <abbr title="real-time communication">RTC</abbr> as used throughout the document and outlines how <abbr title="real-time communication">RTC</abbr> accessibility can support the needs of people with disabilities. It defines the term user needs as used throughout the document and then goes on to list a range of these user needs and their related requirements. Following that some quality related scenarios are outlined and finally a data table that maps the user needs contained in this document to related use case requirements found in other technical specifications.</p>

<p>This document is most explicitly not a collection of baseline requirements. It is also important to note that some of the requirements may be implemented at a system or platform level, and some may be authoring requirements.</p>
</section>

<section id="sotd" class="introductory"><h2>Status of This Document</h2><p><em>This section describes the status of this
      document at the time of its publication. A list of current <abbr title="World Wide Web Consortium">W3C</abbr>
      publications and the latest revision of this technical report can be found
      in the <a href="https://www.w3.org/TR/"><abbr title="World Wide Web Consortium">W3C</abbr> technical reports index</a> at
      https://www.w3.org/TR/.</em></p><p>
    This document was published by the <a href="https://www.w3.org/groups/wg/apa">Accessible Platform Architectures Working Group</a> as
    an Editor's Draft. 
  </p><p>Publication as an Editor's Draft does not
  imply endorsement by <abbr title="World Wide Web Consortium">W3C</abbr> and its Members. </p><p>
    This is a draft document and may be updated, replaced or obsoleted by other
    documents at any time. It is inappropriate to cite this document as other
    than work in progress.
    
  </p><p>
    
        This document was produced by a group
        operating under the
        <a href="https://www.w3.org/Consortium/Patent-Policy/"><abbr title="World Wide Web Consortium">W3C</abbr> Patent
          Policy</a>.
      
    
                <abbr title="World Wide Web Consortium">W3C</abbr> maintains a
                <a rel="disclosure" href="https://www.w3.org/groups/wg/apa/ipr">public list of any patent disclosures</a>
          made in connection with the deliverables of
          the group; that page also includes
          instructions for disclosing a patent. An individual who has actual
          knowledge of a patent which the individual believes contains
          <a href="https://www.w3.org/Consortium/Patent-Policy/#def-essential">Essential Claim(s)</a>
          must disclose the information in accordance with
          <a href="https://www.w3.org/Consortium/Patent-Policy/#sec-Disclosure">section 6 of the <abbr title="World Wide Web Consortium">W3C</abbr> Patent Policy</a>.
        
  </p><p>
                  This document is governed by the
                  <a id="w3c_process_revision" href="https://www.w3.org/2021/Process-20211102/">2 November 2021 <abbr title="World Wide Web Consortium">W3C</abbr> Process Document</a>.
                </p></section><nav id="toc"><h2 class="introductory" id="table-of-contents">Table of Contents</h2><ol class="toc"><li class="tocline"><a class="tocxref" href="#abstract">Abstract</a></li><li class="tocline"><a class="tocxref" href="#sotd">Status of This Document</a></li><li class="tocline"><a class="tocxref" href="#introduction">Introduction</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#what-is-real-time-communication-rtc"> What is real-time communication (<abbr title="real-time communication">RTC</abbr>)? </a></li></ol></li><li class="tocline"><a class="tocxref" href="#real-time-communication-and-accessibility"><bdi class="secno">1. </bdi>Real-time communication and accessibility </a></li><li class="tocline"><a class="tocxref" href="#user-needs-definition"><bdi class="secno">2. </bdi>User needs definition</a></li><li class="tocline"><a class="tocxref" href="#user-needs-and-requirements"><bdi class="secno">3. </bdi>User needs and requirements</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#window-anchoring-and-pinning"><bdi class="secno">3.1 </bdi>Window anchoring and pinning </a></li><li class="tocline"><a class="tocxref" href="#pause-on-record-captioning-in-rtc"><bdi class="secno">3.2 </bdi>Pause 'on record' captioning in <abbr title="real-time communication">RTC</abbr></a></li><li class="tocline"><a class="tocxref" href="#accessibility-user-preferences-and-profiles"><bdi class="secno">3.3 </bdi>Accessibility user preferences and profiles</a></li><li class="tocline"><a class="tocxref" href="#incoming-calls-and-caller-id"><bdi class="secno">3.4 </bdi>Incoming calls and caller ID</a></li><li class="tocline"><a class="tocxref" href="#routing-and-communication-channel-control"><bdi class="secno">3.5 </bdi>Routing and communication channel control</a></li><li class="tocline"><a class="tocxref" href="#audio-description-in-live-conferencing"><bdi class="secno">3.6 </bdi>Audio description in live conferencing</a></li><li class="tocline"><a class="tocxref" href="#quality-synchronisation-and-playback"><bdi class="secno">3.7 </bdi>Quality synchronisation and playback</a></li><li class="tocline"><a class="tocxref" href="#simultaneous-voice-text-signing"><bdi class="secno">3.8 </bdi>Simultaneous voice, text &amp; signing</a></li><li class="tocline"><a class="tocxref" href="#emergency-calls-support-for-real-time-text-rtt"><bdi class="secno">3.9 </bdi>Emergency calls: Support for Real-Time Text (<abbr title="Real-time text">RTT</abbr>) </a></li><li class="tocline"><a class="tocxref" href="#text-and-video-relay-services-vrs"><bdi class="secno">3.10 </bdi>Text and Video relay services (<abbr title="Video relay services">VRS</abbr>)</a></li><li class="tocline"><a class="tocxref" href="#distinguishing-sent-and-received-text-with-rtt"><bdi class="secno">3.11 </bdi>Distinguishing sent and received text with <abbr title="Real-time text">RTT</abbr></a></li><li class="tocline"><a class="tocxref" href="#call-participants-and-status"><bdi class="secno">3.12 </bdi>Call participants and status</a></li><li class="tocline"><a class="tocxref" href="#captioning-support"><bdi class="secno">3.13 </bdi>Captioning support</a></li><li class="tocline"><a class="tocxref" href="#assistance-for-users-with-cognitive-disabilities"><bdi class="secno">3.14 </bdi>Assistance for users with cognitive disabilities</a></li><li class="tocline"><a class="tocxref" href="#personalized-symbol-sets-for-users-with-cognitive-disabilities"><bdi class="secno">3.15 </bdi>Personalized symbol sets for users with cognitive disabilities</a></li><li class="tocline"><a class="tocxref" href="#internet-relay-chat-irc-style-interfaces"><bdi class="secno">3.16 </bdi>Internet relay chat (<abbr title="Internet Relay Chat">IRC</abbr>) style interfaces</a></li></ol></li><li class="tocline"><a class="tocxref" href="#relationship-between-rtc-and-xr-accessibility"><bdi class="secno">4. </bdi>Relationship between <abbr title="real-time communication">RTC</abbr> and XR Accessibility</a></li><li class="tocline"><a class="tocxref" href="#quality-of-service-scenarios"><bdi class="secno">5. </bdi>Quality of service scenarios</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#deaf-users-video-resolution-and-frame-rates"><bdi class="secno">5.1 </bdi>Deaf users: Video resolution and frame rates</a></li><li class="tocline"><a class="tocxref" href="#audio-frequency-bandwidth"><bdi class="secno">5.2 </bdi>Audio frequency bandwidth</a></li></ol></li><li class="tocline"><a class="tocxref" href="#quality-requirements-for-video"><bdi class="secno">6. </bdi>Quality requirements for video </a></li><li class="tocline"><a class="tocxref" href="#c-change-log"><bdi class="secno">A. </bdi>Change Log<span class="formerLink" aria-label="§"></span></a></li><li class="tocline"><a class="tocxref" href="#acknowledgments"><bdi class="secno">B. </bdi>Acknowledgments</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#participants-of-the-apa-working-group-active-in-the-development-of-this-document"><bdi class="secno">B.1 </bdi>Participants of the <abbr title="Accessible Platform Architectures Working Group">APA</abbr> working group active in the development of this document:</a></li><li class="tocline"><a class="tocxref" href="#previously-active-participants-commenters-and-other-contributors"><bdi class="secno">B.2 </bdi>Previously Active Participants, Commenters, and Other Contributors</a></li></ol></li><li class="tocline"><a class="tocxref" href="#enabling-funders"><bdi class="secno">C. </bdi>Enabling funders<span class="formerLink" aria-label="§"></span></a></li><li class="tocline"><a class="tocxref" href="#references"><bdi class="secno">D. </bdi>References</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#informative-references"><bdi class="secno">D.1 </bdi>Informative references</a></li></ol></li></ol></nav>
		<section class="introductory" id="introduction"><div class="header-wrapper"><h2 id="introduction-0">Introduction</h2><a class="self-link" href="#introduction" aria-label="Permalink for this Section"></a></div>
		  
		<section id="what-is-real-time-communication-rtc"><div class="header-wrapper"><h3 id="what-is-real-time-communication-rtc-0"> What is real-time communication (<abbr title="real-time communication">RTC</abbr>)? </h3><a class="self-link" href="#what-is-real-time-communication-rtc" aria-label="Permalink for this Section"></a></div>
<p>Real-time communication (<abbr title="real-time communication">RTC</abbr>) is an evolution beyond the traditional data exchange model of client to server resulting in real-time peer to peer audio, video and data exchange directly between supported user agents. This allows instantaneous applications for video, text and audio calls, text chat, file exchange, screen sharing and gaming, all without the need for browser plug-ins. While real-time communication (<abbr title="real-time communication">RTC</abbr>) applications are enabled in the main by specifications like <abbr title="Web Real-time communication">WebRTC</abbr>, <abbr title="Web Real-time communication">WebRTC</abbr> is not the sole specification with responsibility to enable accessible real-time communication applications. The use cases and requirements are broad - for example as outlined in the <abbr title="Internet Engineering Task Force">IETF</abbr> RFC 7478 'Web Real-Time Communication Use Cases and Requirements' document. [<cite><a class="bibref" data-link-type="biblio" href="#bib-ietf-rtc" title="Web Real-Time Communication Use Cases and Requirements">ietf-rtc</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-webrtc" title="WebRTC 1.0: Real-Time Communication Between Browsers">webrtc</a></cite>]</p>
</section></section>

<section id="real-time-communication-and-accessibility"><div class="header-wrapper"><h2 id="x1-real-time-communication-and-accessibility"><bdi class="secno">1. </bdi>Real-time communication and accessibility </h2><a class="self-link" href="#real-time-communication-and-accessibility" aria-label="Permalink for Section 1."></a></div>

<p><abbr title="real-time communication">RTC</abbr> has the potential to allow improved accessibility features that will support a broad range of user needs for people with a wide range of disabilities. These needs can be met through improved audio and video quality, audio routing, captioning, improved live transcription, transfer of alternate formats such as sign-language, text-messaging / chat, real time user support and status polling.</p>

<p><abbr title="real-time communication">RTC</abbr> accessibility is enabled by a combination of technologies and specifications such as those from the Media Working Group, Web and Networks Interest Group, Second Screen, and Web Audio Working group as well as <abbr title="Accessibility Guidelines Working Group">AGWG</abbr> and <abbr title="Accessible Rich Internet Applications">ARIA</abbr>. The Accessible Platform Architectures Working Group (<abbr title="Accessible Platform Architectures Working Group">APA</abbr>) hopes this document will inform how these groups meet various responsibilities for enabling accessible <abbr title="real-time communication">RTC</abbr>, as well updating related use cases in various groups. For examples, view the current work on <abbr title="Web Real-time communication">WebRTC</abbr> Next Version Use Cases First Public Working Draft. [<cite><a class="bibref" data-link-type="biblio" href="#bib-webrtc-use-cases" title="WebRTC Next Version Use Cases">webrtc-use-cases</a></cite>]</p>
		</section>

		<section id="user-needs-definition"><div class="header-wrapper"><h2 id="x2-user-needs-definition"><bdi class="secno">2. </bdi>User needs definition</h2><a class="self-link" href="#user-needs-definition" aria-label="Permalink for Section 2."></a></div>

<p>This document outlines various accessibility related user needs for <abbr title="real-time communication">RTC</abbr> accessibility. The term 'user needs' in this document relates to what people with various disabilities need to successfully use <abbr title="real-time communication">RTC</abbr> applications. These needs may relate to having particular supports in an application, being able to complete tasks or access other functions. These user needs should drive accessibility requirements for <abbr title="real-time communication">RTC</abbr> accessibility and its related architecture.</p>

<p>User needs are presented here with their related requirements; some in a range of scenarios (which can be thought of as similar to user stories).</p>
		</section>

<section id="user-needs-and-requirements"><div class="header-wrapper"><h2 id="x3-user-needs-and-requirements"><bdi class="secno">3. </bdi>User needs and requirements</h2><a class="self-link" href="#user-needs-and-requirements" aria-label="Permalink for Section 3."></a></div>

<p>The following outlines a range of user needs and requirements. The user needs have also been compared to existing use cases for real-time text (<abbr title="Real-time text">RTT</abbr>) such as the <abbr title="Internet Engineering Task Force">IETF</abbr> 'Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)' RFC 5194 and the European Procurement Standard EN 301 549. [<cite><a class="bibref" data-link-type="biblio" href="#bib-rtt-sip" title="Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)">rtt-sip</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-en301-549" title="Accessibility requirements for ICT products and services">EN301-549</a></cite>]</p>
		<section id="window-anchoring-and-pinning"><div class="header-wrapper"><h3 id="x3-1-window-anchoring-and-pinning"><bdi class="secno">3.1 </bdi>Window anchoring and pinning </h3><a class="self-link" href="#window-anchoring-and-pinning" aria-label="Permalink for Section 3.1"></a></div>

			
			<ul>
<li><strong>User Need 1:</strong> A deaf or hard of hearing user needs to anchor or pin certain windows in an <abbr title="real-time communication">RTC</abbr> application so both a sign language interpreter and the person speaking (whose speech is being interpreted) are simultaneously visible.</li>

<li><strong>REQ 1a:</strong> Provide the ability to anchor or pin specific windows so the user can associate the sign language interpreter with the correct speaker.</li>
<li><strong>REQ 1b:</strong> Allow the use of flexible pinning of captions or other related content alternatives. This may be to second screen devices.</li>
<li><strong>REQ 1c:</strong> Ensure the source of any captions, transcriptions or other alternatives is clear to the user, even when second screen devices are used.</li>
<li><strong>REQ 1d:</strong> Atomic pieces of data such as information regarding the person currently speaking, activities such as the people entering or leaving a meeting, or the last message posted in the chat channel, can be pinned to a user interface.</li>
<li><strong>REQ 1e:</strong> For pinned content, there is a need to handle and support the metadata that allows the client engine to re-aggregate or re-route any pinned content.</li>
<li><strong>REQ 1f:</strong> A user should have the ability to change the size of the window especially for sign language interpreters, certified deaf interpreters, and signing people.</li>
</ul>

<div class="note" role="note" id="issue-container-generatedID"><div role="heading" class="note-title marker" id="h-note" aria-level="4"><span>Note</span></div><p class="">
Not all atomic items necessarily are pinned next to other atomic elements but some may be dependent, related or updated synchronously. For example, if there are multiple atomic data points destined for an 80 character braille display that has been sectioned to display 4 atomic items in up to 19 spaces each (leaving at least one blank cell for spacing).
</p></div>

<div class="note" role="note" id="issue-container-generatedID-0"><div role="heading" class="note-title marker" id="h-note-0" aria-level="4"><span>Note</span></div><p class="">
Here the term atomic relates to small pieces of data. For the purposes of accessibility conformance testing, the definitions and use of the terms 'atomic' and 'atomic rules' may also be useful. [<cite><a class="bibref" data-link-type="biblio" href="#bib-applicability-atomic" title="Accessibility Conformance Testing (ACT) Rules Format 1.0 - W3C Recommendation, 31 October 2019">applicability-atomic</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-rule-types" title="Accessibility Conformance Testing (ACT) Rules Format 1.0 - W3C Recommendation, 31 October 2019">rule-types</a></cite>]
</p></div>

</section>

<section id="pause-on-record-captioning-in-rtc"><div class="header-wrapper"><h3 id="x3-2-pause-on-record-captioning-in-rtc"><bdi class="secno">3.2 </bdi>Pause 'on record' captioning in <abbr title="real-time communication">RTC</abbr></h3><a class="self-link" href="#pause-on-record-captioning-in-rtc" aria-label="Permalink for Section 3.2"></a></div>


<ul>
<li><strong>User Need 2:</strong> A deaf or hard of hearing user may need captioning of content to be private in a meeting or presentation.</li>
<li><strong>REQ 2a:</strong>  Ensure there is a host operable toggle in the captioning service (whether human or automated) that facilitates going on and off record for the preserved transcript, but continues to provide captions meanwhile for 'off record' conversations.</li>
<li><strong>REQ 2b:</strong> Ensure the toggle between saving recordings also applies to the saving of captions. There should be a mechanism that both audio and captions can be paused or stopped, and both can be simultaneously restored for recording. </li>
</ul>
</section>

<section id="accessibility-user-preferences-and-profiles"><div class="header-wrapper"><h3 id="x3-3-accessibility-user-preferences-and-profiles"><bdi class="secno">3.3 </bdi>Accessibility user preferences and profiles</h3><a class="self-link" href="#accessibility-user-preferences-and-profiles" aria-label="Permalink for Section 3.3"></a></div>



<ul>
<li><strong>User Need 3:</strong> A user may need to change device or environment and have their accessibility user preferences preserved.</li>
<li><strong>REQ 3a:</strong> Ensure user profiles and accessibility preferences in <abbr title="real-time communication">RTC</abbr> applications are mobile and can move with the user as they change device or environment.</li>
</ul>
</section>

<section id="incoming-calls-and-caller-id"><div class="header-wrapper"><h3 id="x3-4-incoming-calls-and-caller-id"><bdi class="secno">3.4 </bdi>Incoming calls and caller ID</h3><a class="self-link" href="#incoming-calls-and-caller-id" aria-label="Permalink for Section 3.4"></a></div>


<ul>
<li><strong>User Need 4:</strong> A screen-reader user or user with a cognitive impairment needs to know a call is incoming and needs to recognise the ID of the caller. A deaf or hard of hearing user may also need to identify an incoming relay call.</li>

<li><strong>REQ 4a:</strong> Provide indication of incoming calls in an unobtrusive way via a symbol set or other browser notification.</li> 
<li><strong>REQ 4b:</strong> Alert assistive technologies via relevant APIs.</li>
<li><strong>REQ 4c:</strong> Support the presentation and display of call prefix information for relay calls.</li>
</ul> 

<div class="note" role="note" id="issue-container-generatedID-1"><div role="heading" class="note-title marker" id="h-note-1" aria-level="4"><span>Note</span></div><p class="">
Successful design of operations required for acting on incoming calls, getting informed about who the caller is and connecting relay services should not require complicated sequences of user actions. </p></div>
</section>

<section id="routing-and-communication-channel-control"><div class="header-wrapper"><h3 id="x3-5-routing-and-communication-channel-control"><bdi class="secno">3.5 </bdi>Routing and communication channel control</h3><a class="self-link" href="#routing-and-communication-channel-control" aria-label="Permalink for Section 3.5"></a></div>
		
<ul>
<li><strong>User Need 5:</strong> A user of speech and Augmentative and Alternative Communication (<abbr title="Augmentative and Alternative Communication">AAC</abbr>), or a blind user of screen reader and braille output devices simultaneously, will need to manage audio and other output separately.</li>
<li><strong>REQ 5a:</strong> Provide or support a range of browser level audio output options.</li> 
<li><strong>REQ 5b:</strong> Allow controlled routing of alerts and other browser output to a braille device or other hardware.</li>
</ul>

<ul>
<li><strong>User Need 6:</strong> A deaf user needs to move parts of a live teleconference session (as separate streams) to one or more devices for greater control.</li>

<li><strong>REQ 6a:</strong> Allow the separate routing of video streams such as, captioning or a sign language interpreter to a separate high resolution display.</li>
</ul>


<ul>
<li><strong>User Need 7:</strong> Users with cognitive disabilities or blind users may have relative volume levels set as preferences that relate to importance, urgency or meaning.</li>

<li><strong>REQ 7a:</strong> Allow the panning or setting of relative levels of different audio output. </li>
<li><strong>REQ 7b:</strong> Support multichannel audio in the browser. </li>
</ul>

</section>

		<section id="audio-description-in-live-conferencing"><div class="header-wrapper"><h3 id="x3-6-audio-description-in-live-conferencing"><bdi class="secno">3.6 </bdi>Audio description in live conferencing</h3><a class="self-link" href="#audio-description-in-live-conferencing" aria-label="Permalink for Section 3.6"></a></div>
 
<ul>
<li><strong>User Need 8:</strong> A user may struggle to hear audio description in a live teleconferencing situation.</li>
 <li><strong>REQ 8a:</strong> Ensure Audio Description (AD) recommended sound values are dynamic and have independent volume, EQ adjustment and routing capability.</li>
 <li><strong>REQ 8b:</strong> Support a users custom EQ profile.</li>
 <li><strong>REQ 8c:</strong> If not transmitted in a live screen share - ensure the platform doesn't strip captions or descriptions that may have been part of the original video.</li>
</ul>
<div class="note" role="note" id="issue-container-generatedID-2"><div role="heading" class="note-title marker" id="h-note-2" aria-level="4"><span>Note</span></div><p class="">
 Moving beyond mono in this context is also important, as the stereo spread allows audio descriptions to be sound staged. Applications should also inherit customization settings from the user's operating system.
</p></div>
		</section>

		<section id="quality-synchronisation-and-playback"><div class="header-wrapper"><h3 id="x3-7-quality-synchronisation-and-playback"><bdi class="secno">3.7 </bdi>Quality synchronisation and playback</h3><a class="self-link" href="#quality-synchronisation-and-playback" aria-label="Permalink for Section 3.7"></a></div>



<ul>
<li><strong>User Need 9:</strong> Any user watching captioning or audio description needs to be confident it is synchronised and accurate.</li>
<li><strong>REQ 9a:</strong> Ensure that any outages or loss to captioning or audio description will be repaired while preserving context and meaning. </li>
<li><strong>REQ 9b:</strong> Ensure that the integrity of related alternate supporting tracks or streams such as transcriptions, are in sync with any repairs.</li>
</ul>
		</section>

		<section id="simultaneous-voice-text-signing"><div class="header-wrapper"><h3 id="x3-8-simultaneous-voice-text-signing"><bdi class="secno">3.8 </bdi>Simultaneous voice, text &amp; signing</h3><a class="self-link" href="#simultaneous-voice-text-signing" aria-label="Permalink for Section 3.8"></a></div>


<ul>
<li><strong>User Need 10:</strong> A deaf user needs to simultaneously talk on a call, send and receive real-time text and/or instant messages via a text interface and watch sign language using a video stream.</li>

<li><strong>REQ 10a:</strong> Ensure support for multiple simultaneous streams. </li>

</ul>

<div class="note" role="note" id="issue-container-generatedID-3"><div role="heading" class="note-title marker" id="h-note-3" aria-level="4"><span>Note</span></div><p class="">
This user need may also indicate necessary support for 'Total conversation' services as defined by <abbr title="International Telecommunication Union">ITU</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr> applications. These are combinations of voice, video, and <abbr title="Real-time text">RTT</abbr> in the same real-time session. [<cite><a class="bibref" data-link-type="biblio" href="#bib-total-conversation" title="ITU-T SG 16 Work on Accessibility - Total Conversation">total-conversation</a></cite>]
</p></div>
		</section>

		<section id="emergency-calls-support-for-real-time-text-rtt"><div class="header-wrapper"><h3 id="x3-9-emergency-calls-support-for-real-time-text-rtt"><bdi class="secno">3.9 </bdi>Emergency calls: Support for Real-Time Text (<abbr title="Real-time text">RTT</abbr>) </h3><a class="self-link" href="#emergency-calls-support-for-real-time-text-rtt" aria-label="Permalink for Section 3.9"></a></div>



<ul>
<li><strong>User Need 11:</strong> In an emergency situation an Augmentative and Alternative Communication (<abbr title="Augmentative and Alternative Communication">AAC</abbr>) user, deaf, speech impaired, hard of hearing or deaf blind user needs to make an emergency call, instantly send and receive related text messages and/or sign via a video stream.</li>

<li><strong>REQ 11a:</strong> Provide or ensure support for <abbr title="Real-time text">RTT</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr>. </li>
	<li><strong>REQ 11b:</strong> Avoid the problem of unsent emergency messages. A user may not be aware when they have not successfully sent an emergency message. For example, <abbr title="Real-time text">RTT</abbr> avoids this problem due to instantaneous data transfer but this may be an issue for other messaging methods or platforms. </li>
</ul>
		</section>

		<section id="text-and-video-relay-services-vrs"><div class="header-wrapper"><h3 id="x3-10-text-and-video-relay-services-vrs"><bdi class="secno">3.10 </bdi>Text and Video relay services (<abbr title="Video relay services">VRS</abbr>)</h3><a class="self-link" href="#text-and-video-relay-services-vrs" aria-label="Permalink for Section 3.10"></a></div>



<ul>
<li><strong>User Need 12:</strong> A deaf, speech impaired, or hard of hearing user, needs to communicate on a call using a remote video interpretation service (<abbr title="Video remote interpretation">VRI</abbr>) to access sign language and interpreter services.</li>

<li><strong>REQ 12a:</strong> Provide or ensure support for video relay and remote interpretation services. This user need may relate to interoperability with third-party services;  <abbr title="Internet Engineering Task Force">IETF</abbr> has looked at standardizing a way to use Session Initiation Protocol (SIP) with <abbr title="Video relay services">VRS</abbr> services. [<cite><a class="bibref" data-link-type="biblio" href="#bib-ietf-relay" title="Interoperability Profile for Relay User Equipment">ietf-relay</a></cite>] </li>
<li><strong>REQ 12b:</strong> Provide <abbr title="Video relay services">VRS</abbr> and <abbr title="Video remote interpretation">VRI</abbr> support for different specified sign languages and various spoken language translations. A user may also need to stream or pin both.</li>
<li><strong>REQ 12c:</strong> Ensure that privacy and security options are maintained when using relay services.</li> 
</ul>

<div class="note" role="note" id="issue-container-generatedID-4"><div role="heading" class="note-title marker" id="h-note-4" aria-level="4"><span>Note</span></div><p class="">To successfully connect video or text relay services should not require a complicated sequence of user actions.</p></div>


</section>


		<section id="distinguishing-sent-and-received-text-with-rtt"><div class="header-wrapper"><h3 id="x3-11-distinguishing-sent-and-received-text-with-rtt"><bdi class="secno">3.11 </bdi>Distinguishing sent and received text with <abbr title="Real-time text">RTT</abbr></h3><a class="self-link" href="#distinguishing-sent-and-received-text-with-rtt" aria-label="Permalink for Section 3.11"></a></div>


<ul>
<li><strong>User Need 13:</strong> A deaf or deaf blind user needs to tell the difference between incoming text and outgoing text.</li>
<li><strong>REQ 13a:</strong> Ensure when used with <abbr title="Real-time text">RTT</abbr> functionality, <abbr title="Web Real-time communication">WebRTC</abbr> handles the routing of this information to a format or output of the users choosing.</li>
</ul>
		</section>
	
		<section id="call-participants-and-status"><div class="header-wrapper"><h3 id="x3-12-call-participants-and-status"><bdi class="secno">3.12 </bdi>Call participants and status</h3><a class="self-link" href="#call-participants-and-status" aria-label="Permalink for Section 3.12"></a></div>
 
<ul>
<li><strong>User Need 14: </strong> In a teleconference a user needs to know what participants are on the call, as well as their status.</li>
<li><strong>REQ 14a:</strong> Ensure participant details such as name and status; whether the person is muted or talking is accessible to users of assistive technologies.</li>
<li><strong>REQ 14b:</strong> Ensure participant metadata such as their name, their affiliation or other relevant information, is correctly associated with the meeting record and can be preserved for review after the call. This should be done with the participants consent.</li>
</ul>
		</section>

		<section id="captioning-support"><div class="header-wrapper"><h3 id="x3-13-captioning-support"><bdi class="secno">3.13 </bdi>Captioning support</h3><a class="self-link" href="#captioning-support" aria-label="Permalink for Section 3.13"></a></div>


<ul>
<li><strong>User Need 15:</strong> A deaf user or user with a cognitive disability needs to access a channel containing live transcriptions during a conference call or broadcast.</li>
 <li><strong>REQ 15a:</strong> Honor user preferences relating to captioned content. Provide support for signing or use of symbol sets e.g. Augmentative and Alternative Communication (<abbr title="Augmentative and Alternative Communication">AAC</abbr>).</li>
</ul>
		</section>

		<section id="assistance-for-users-with-cognitive-disabilities"><div class="header-wrapper"><h3 id="x3-14-assistance-for-users-with-cognitive-disabilities"><bdi class="secno">3.14 </bdi>Assistance for users with cognitive disabilities</h3><a class="self-link" href="#assistance-for-users-with-cognitive-disabilities" aria-label="Permalink for Section 3.14"></a></div>


<ul>
<li><strong>User Need 16: </strong> Users with cognitive disabilities may need assistance when using audio or video communication. </li>
 <li><strong>REQ 16a:</strong> Ensure a <abbr title="Web Real-time communication">WebRTC</abbr> video call can host a technical or user support channel.</li>
  <li><strong>REQ 16b:</strong> Provide support that is customised to the needs of the user. This may be via a relay service or speech-speech-relay-service.</li>
</ul>

		</section>

		<section id="personalized-symbol-sets-for-users-with-cognitive-disabilities"><div class="header-wrapper"><h3 id="x3-15-personalized-symbol-sets-for-users-with-cognitive-disabilities"><bdi class="secno">3.15 </bdi>Personalized symbol sets for users with cognitive disabilities</h3><a class="self-link" href="#personalized-symbol-sets-for-users-with-cognitive-disabilities" aria-label="Permalink for Section 3.15"></a></div>



<ul>
<li><strong>User Need 17: </strong> Users with cognitive disabilities may need to use symbol sets or <abbr title="Augmentative and Alternative Communication">AAC</abbr> for identifying functions available in a <abbr title="Web Real-time communication">WebRTC</abbr> enabled client for voice, file or data transfer.</li>

  <li><strong>REQ 17a:</strong> Provide personalization support for symbols set replacements of existing user interface rendering of current functions or controls.</li>
</ul>

<div class="note" role="note" id="issue-container-generatedID-5"><div role="heading" class="note-title marker" id="h-note-5" aria-level="4"><span>Note</span></div><p class="">This relates to cognitive accessibility requirements. For related work at <abbr title="World Wide Web Consortium">W3C</abbr> see the 'Personalization Semantics Content Module 1.0' and 'Media Queries Level 5'. [<cite><a class="bibref" data-link-type="biblio" href="#bib-personalization" title="Personalization Semantics Content Module 1.0">personalization</a></cite>] [<cite><a class="bibref" data-link-type="biblio" href="#bib-media-queries" title="Media Queries Level 5">media-queries</a></cite>]</p></div>

</section>

<section id="internet-relay-chat-irc-style-interfaces"><div class="header-wrapper"><h3 id="x3-16-internet-relay-chat-irc-style-interfaces"><bdi class="secno">3.16 </bdi>Internet relay chat (<abbr title="Internet Relay Chat">IRC</abbr>) style interfaces</h3><a class="self-link" href="#internet-relay-chat-irc-style-interfaces" aria-label="Permalink for Section 3.16"></a></div>

	
		

<ul>
<li><strong>User Need 18: </strong> To translate text to speech interactions into comprehensible speech; a blind screen reader user depending on text to speech (<abbr title="Text to Speech">TTS</abbr>) to interact with their computers and smart devices needs a traditional Internet relay chat (<abbr title="Internet relay chat">IRC</abbr>) style interface.</li>

	  <li><strong>REQ 18a:</strong> Preserve <abbr title="Internet relay chat">IRC</abbr> as a configuration option in user agents that implement <abbr title="Web Real-time communication">WebRTC</abbr> as opposed to having only the real-time text type interface. <abbr title="Real-time text">RTT</abbr> is favoured by users who are deaf or hearing impaired.  For screen reader users, <abbr title="Text to Speech">TTS</abbr> cannot reasonably translate text into comprehensible speech unless characters are transmitted in very close timing to one another. Typical gaps will result in stuttering and highly unintelligible speech output from the <abbr title="Text to Speech">TTS</abbr> engine.</li>
</ul>

<div class="note" role="note" id="issue-container-generatedID-6"><div role="heading" class="note-title marker" id="h-note-6" aria-level="4"><span>Note</span></div><p class=""> Some braille users will also prefer the <abbr title="Real-time text">RTT</abbr> model. However, braille users desiring text displayed with standard contracted braille might better be served in the manner users relying on <abbr title="Text to Speech">TTS</abbr> engines are served, by buffering the data to be transmitted until an end of line character is reached.</p></div>
		</section>

</section>
<section id="relationship-between-rtc-and-xr-accessibility"><div class="header-wrapper"><h2 id="x4-relationship-between-rtc-and-xr-accessibility"><bdi class="secno">4. </bdi>Relationship between <abbr title="real-time communication">RTC</abbr> and XR Accessibility</h2><a class="self-link" href="#relationship-between-rtc-and-xr-accessibility" aria-label="Permalink for Section 4."></a></div>
	

<p>There are potential real-time communication application issues that may only apply in immersive environments or augmented reality contexts.</p>

<p>For example, if an <abbr title="real-time communication">RTC</abbr> application is also an XR application then relevant XR accessibility requirements should be addressed as well. [<cite><a class="bibref" data-link-type="biblio" href="#bib-xaur" title="XR Accessibility User Requirements">xaur</a></cite>]</p>

</section>

		
<section id="quality-of-service-scenarios"><div class="header-wrapper"><h2 id="x5-quality-of-service-scenarios"><bdi class="secno">5. </bdi>Quality of service scenarios</h2><a class="self-link" href="#quality-of-service-scenarios" aria-label="Permalink for Section 5."></a></div>
	
	<section id="deaf-users-video-resolution-and-frame-rates"><div class="header-wrapper"><h3 id="x5-1-deaf-users-video-resolution-and-frame-rates"><bdi class="secno">5.1 </bdi>Deaf users: Video resolution and frame rates</h3><a class="self-link" href="#deaf-users-video-resolution-and-frame-rates" aria-label="Permalink for Section 5.1"></a></div>


<p><strong>Scenario:</strong> A deaf user watching a signed broadcast needs a high-quality frame rate to maintain legibility and clarity in order to understand what is being signed.</p>

<div class="note" role="note" id="issue-container-generatedID-7"><div role="heading" class="note-title marker" id="h-note-7" aria-level="4"><span>Note</span></div><p class="">EN 301 549 Section 6,  recommends  <abbr title="Web Real-time communication">WebRTC</abbr> applications should support a frame rate of at least 20 frames per second (FPS). More details can be found at <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf"> Accessible Procurement standard for ICT products and services EN 301 549 (PDF)</a> and <abbr title="International Telecommunication Union">ITU</abbr>-T Series H Supplement 1 "<a href="https://www.itu.int/ITU-T/recommendations/rec.aspx?rec=4834&amp;lang=en">Sign language and lip-reading real-time conversation using low bit-rate video communication</a>".</p></div>

</section>

<section id="audio-frequency-bandwidth"><div class="header-wrapper"><h3 id="x5-2-audio-frequency-bandwidth"><bdi class="secno">5.2 </bdi>Audio frequency bandwidth</h3><a class="self-link" href="#audio-frequency-bandwidth" aria-label="Permalink for Section 5.2"></a></div>
	

<p><strong>Scenario:</strong> A hard of hearing user needs better stereo sound to have a quality experience in work calls or meetings with friends or family. Transmission aspects, such as decibel range for audio needs to be of high-quality. For calls, industry allows higher audio resolution but still mostly in mono only. </p>

<div class="note" role="note" id="issue-container-generatedID-8"><div role="heading" class="note-title marker" id="h-note-8" aria-level="4"><span>Note</span></div><p class="">EN 301 549 Section 6, recommends for <abbr title="Web Real-time communication">WebRTC</abbr> enabled conferencing and communication the application shall be able to encode and decode communication with a frequency range with an upper limit of at least 7KHz. More details can be found at <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf"> Accessible Procurement standard for ICT products and services EN 301 549 (PDF)</a></p></div>
</section>
</section>

<section id="quality-requirements-for-video"><div class="header-wrapper"><h2 id="x6-quality-requirements-for-video"><bdi class="secno">6. </bdi>Quality requirements for video </h2><a class="self-link" href="#quality-requirements-for-video" aria-label="Permalink for Section 6."></a></div>



<p><strong>Scenario:</strong> A hard of hearing user needs better stereo sound so they can have a quality experience in watching HD video or having a HD meeting with friends or family. Similarly for video quality, transmission aspects such as frames per second needs to be of high-quality.</p>

<div class="note" role="note" id="issue-container-generatedID-9"><div role="heading" class="note-title marker" id="h-note-9" aria-level="3"><span>Note</span></div><p class="">A hard of hearing user often combines their perception of speech from audio with their perception of lip movement and other visual clues to create an overall understanding of speech. For the visual parts, the requirements on video are the same as expressed in '5.1 Deaf users: Video resolution and frame rates' about perception of sign language because lip movements are also part of sign language, equally rapid and as detailed as the other parts of sign language.</p></div>

<div class="note" role="note" id="issue-container-generatedID-10"><div role="heading" class="note-title marker" id="h-note-10" aria-level="3"><span>Note</span></div><p class="">EN 301 549 Section 6,  recommends for <abbr title="Web Real-time communication">WebRTC</abbr> enabled conferencing and communication the application shall be able to encode and decode communication with a frequency range with an upper limit of at least 7KHz. More details can be found at <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf"> Accessible Procurement standard for ICT products and services EN 301 549 (PDF)</a></p></div>

<div class="note" role="note" id="issue-container-generatedID-11"><div role="heading" class="note-title marker" id="h-note-11" aria-level="3"><span>Note</span></div><p class=""><abbr title="Web Real-time communication">WebRTC</abbr> lets applications prioritise bandwidth dedicated to audio / video / data streams; there is also some experimental work in signalling these needs to the network layer as well as support for prioritising frame rate over resolution in case of congestion. [<cite><a class="bibref" data-link-type="biblio" href="#bib-webrtc-priority" title="WebRTC DSCP Control API">webrtc-priority</a></cite>]</p></div>

</section>


<section class="appendix" id="change-log"><div class="header-wrapper"><h2 id="c-change-log"><bdi class="secno">A. </bdi>Change Log<a class="self-link" aria-label="§" href="#change-log"></a></h2><a class="self-link" href="#c-change-log" aria-label="Permalink for Appendix A."></a></div>
			

<p>The following is a list of new user needs and requirements since the publication of the <a href="https://www.w3.org/TR/2020/WD-raur-20200319/">previous working draft</a>:</p>

<ul>
	<li><strong>Window anchoring and pinning:</strong> A deaf or hard of hearing user needs to anchor or pin certain windows in an <abbr title="real-time communication">RTC</abbr>  application so both a sign language interpreter and the person speaking (whose speech is being interpreted) are simultaneously visible.</li>
<li><strong>REQ 1a:</strong> Provide the ability to anchor or pin specific windows so the user can associate the sign language interpreter with the correct speaker.</li>
<li><strong>REQ 1b:</strong> Allow the use of flexible pinning of captions or other related content alternatives. This may be to second screen devices.</li>
<li><strong>REQ 1c:</strong> Ensure the source of any captions, transcriptions or other alternatives is clear to the user, even when second screen devices are used.</li>
<li><strong>REQ 1d:</strong> Atomic pieces of data such as information regarding the person currently speaking, activities such as the people entering or leaving a meeting, or the last message posted in the chat channel, can be pinned to a user interface.</li>
<li><strong>REQ 1e:</strong> For pinned content, there is a need to handle and support the metadata that allows the client engine to re-aggregate or re-route any pinned content.</li>
	<li><strong>Pause 'on record' captioning in <abbr title="real-time communication">RTC</abbr> :</strong> A deaf or hard of hearing user may need captioning of content to be private in a meeting or presentation.</li>
<li><strong>REQ 2a:</strong> Ensure there is a host operable toggle in the captioning service (whether human or automated) that facilitates going on and off record for the preserved transcript, but continues to provide captions meanwhile for 'off record' conversations.</li>
<li><strong>REQ 2b:</strong> Ensure the toggle between saving recordings also applies to the saving of captions. There should be a mechanism that both audio and captions can be paused or stopped, and both can be simultaneously restored for recording.</li>

</ul>

<ul>
	<li><strong>Accessibility user preferences and profiles:</strong> A user may need to change device or environment and have their accessibility user preferences preserved.</li>
<li><strong>REQ 3a:</strong> Ensure user profiles and accessibility preferences in <abbr title="real-time communication">RTC</abbr>  applications are mobile and can move with the user as they change device or environment.</li>

</ul>

<p>The following is a list of updated requirements to existing user needs:</p>

<ul>

 <li><strong>Incoming calls and caller ID - REQ 4c:</strong> Support the presentation and display of call prefix information for relay calls.</li>
 <li><strong>Audio description in live conferencing - REQ 8b:</strong> Support a users custom EQ profile.</li>
 <li><strong>Audio description in live conferencing - REQ 8c:</strong> If not transmitted in a live screen share - ensure the platform doesn't strip captions or descriptions that may have been part of the original video.</li>

	<li><strong>Emergency calls and <abbr title="Real-time text">RTT</abbr> - REQ 11b:</strong>  Avoid the problem of unsent emergency messages. A user may not be aware when they have not successfully sent an emergency message. For example, <abbr title="Real-time text">RTT</abbr> avoids this problem due to instantaneous data transfer but this may be an issue for other messaging methods or platforms. </li>

<li><strong>Video relay services (<abbr title="Video relay services">VRS</abbr>) and video remote interpretation (<abbr title="Video remote interpretation">VRI</abbr>) - REQ 12b:</strong> Provide support for other sign languages and translations. For example, <abbr title="Video relay services">VRS</abbr> calls may be made between a sign language user and a person speaking another language. There are variations in signing itself such as Irish Sign Language (ISL),  which is related to French sign language, and British Sign Language (BSL). A user may need to stream or pin both.</li>
<li><strong>Video relay services (<abbr title="Video relay services">VRS</abbr>) and video remote interpretation (<abbr title="Video remote interpretation">VRI</abbr>) - REQ 12c:</strong> Ensure that privacy and security options are maintained when using relay services. </li> 
</ul>

<p>The following are other changes in this document:</p>

<ul>
	<li>Changed the title of 'Dynamic audio description values in live conferencing' to 'Audio description in live conferencing'.</li>
	<li>New note on the relationship between <abbr title="real-time communication">RTC</abbr>  and <a href="https://www.w3.org/TR/xaur/">XR Accessibility User Requirements</a>.</li>
<li>New note on personalization semantics and CSS media queries.</li>
<li>Moved 'User Need 19:  A deaf user watching a signed broadcast needs a high-quality frame rate to maintain legibility and clarity in order to understand what is being signed' to the 'Quality of service issues' section.</li>
<li>Added note on <abbr title="International Telecommunication Union">ITU</abbr> definition of Total Conversation services that relates to 'REQ 10a: Ensure support for multiple simultaneous streams'.</li>
</ul> 

<div class="note" role="note" id="issue-container-generatedID-12"><div role="heading" class="note-title marker" id="h-note-12" aria-level="3"><span>Note</span></div><p class="">This user need may also indicate necessary support for 'Total conversation' services as defined by <abbr title="International Telecommunication Union">ITU</abbr> in <abbr title="Web Real-time communication">WebRTC</abbr> applications. These are combinations of voice, video, and <abbr title="Real-time text">RTT</abbr> in the same real-time session. [total-conversation]</p></div>

<p>This document has been updated based on document feedback, discussion and Research Questions Task Force consensus.</p>
</section>


	<section class="appendix" id="acknowledgments"><div class="header-wrapper"><h2 id="b-acknowledgments"><bdi class="secno">B. </bdi>Acknowledgments</h2><a class="self-link" href="#acknowledgments" aria-label="Permalink for Appendix B."></a></div>
			
			<section id="participants-of-the-apa-working-group-active-in-the-development-of-this-document"><div class="header-wrapper"><h3 id="b-1-participants-of-the-apa-working-group-active-in-the-development-of-this-document"><bdi class="secno">B.1 </bdi>Participants of the <abbr title="Accessible Platform Architectures Working Group">APA</abbr> working group active in the development of this document:</h3><a class="self-link" href="#participants-of-the-apa-working-group-active-in-the-development-of-this-document" aria-label="Permalink for Appendix B.1"></a></div>
				
				<ul>
					<li>Shadi Abou-Zahra, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Judy Brewer, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Michael Cooper, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Scott Hollier, Edith Cowan University &amp; Centre For Accessibility</li>
					<li>Stephen Noble, Pearson Plc</li>
					<li>Joshue O'Connor, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>John Paton, Royal National Institute of Blind People</li>
					<li>Janina Sajka, Invited Expert</li>
					<li>Jason White, Educational Testing Service</li>

				</ul>
				</section>
<section id="previously-active-participants-commenters-and-other-contributors"><div class="header-wrapper"><h3 id="b-2-previously-active-participants-commenters-and-other-contributors"><bdi class="secno">B.2 </bdi>Previously Active Participants, Commenters, and Other Contributors</h3><a class="self-link" href="#previously-active-participants-commenters-and-other-contributors" aria-label="Permalink for Appendix B.2"></a></div>
				
				<ul>
					<li>Lidia Best, <abbr title="International Telecommunication Union">ITU</abbr>-T</li>
					<li>Wendy Dannels, National Technical Institute for the Deaf</li>
					<li>Dominique Hazael-Massieux, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Gunnar Hellström, Omnitor</li>
					<li>Masahito Kawamori, <abbr title="International Telecommunication Union">ITU</abbr>-T</li>
					<li>Steve Lee, <abbr title="World Wide Web Consortium">W3C</abbr></li>
					<li>Estella Oncins Noguer, TransMedia UAB</li>
					<li>Lisa Seeman, Invited Expert</li>		
				</ul>
</section>
</section>

<section id="enabling-funders"><div class="header-wrapper"><h2 id="c-enabling-funders"><bdi class="secno">C. </bdi>Enabling funders<a class="self-link" aria-label="§" href="#enabling-funders"></a></h2><a class="self-link" href="#enabling-funders" aria-label="Permalink for Section C."></a></div>

<p>This work is supported by the <a href="https://www.w3.org/WAI/about/projects/wai-guide/">EC-funded WAI-Guide Project</a>.</p>
	</section>

	





<section id="references" class="appendix"><div class="header-wrapper"><h2 id="d-references"><bdi class="secno">D. </bdi>References</h2><a class="self-link" href="#references" aria-label="Permalink for Appendix D."></a></div>
  <section id="informative-references"><div class="header-wrapper"><h3 id="d-1-informative-references"><bdi class="secno">D.1 </bdi>Informative references</h3><a class="self-link" href="#informative-references" aria-label="Permalink for Appendix D.1"></a></div>
    
    <dl class="bibliography"><dt id="bib-applicability-atomic">[applicability-atomic]</dt><dd>
      <a href="https://www.w3.org/TR/act-rules-format/#applicability-atomic"><cite>Accessibility Conformance Testing (ACT) Rules Format 1.0 - W3C Recommendation, 31 October 2019</cite></a>. Wilco Fiers; Maureen Kraft; Mary Jo Mueller ; Shadi Abou-Zahra.  W3C. 2019. URL: <a href="https://www.w3.org/TR/act-rules-format/#applicability-atomic">https://www.w3.org/TR/act-rules-format/#applicability-atomic</a>
    </dd><dt id="bib-en301-549">[EN301-549]</dt><dd>
      <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf"><cite>Accessibility requirements for ICT products and services</cite></a>.  CEN/CENELEC/ETSI. March 2021. URL: <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf">https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf</a>
    </dd><dt id="bib-ietf-relay">[ietf-relay]</dt><dd>
      <a href="https://tools.ietf.org/html/draft-ietf-rum-rue-02.html"><cite>Interoperability Profile for Relay User Equipment</cite></a>.  IETF. August 2020. URL: <a href="https://tools.ietf.org/html/draft-ietf-rum-rue-02.html">https://tools.ietf.org/html/draft-ietf-rum-rue-02.html</a>
    </dd><dt id="bib-ietf-rtc">[ietf-rtc]</dt><dd>
      <a href="https://tools.ietf.org/html/rfc7478"><cite>Web Real-Time Communication Use Cases and Requirements</cite></a>.  IETF. March 2015. URL: <a href="https://tools.ietf.org/html/rfc7478">https://tools.ietf.org/html/rfc7478</a>
    </dd><dt id="bib-media-queries">[media-queries]</dt><dd>
      <a href="https://www.w3.org/TR/mediaqueries-5/"><cite>Media Queries Level 5</cite></a>.  W3C. 31 July 2020. URL: <a href="https://www.w3.org/TR/mediaqueries-5/">https://www.w3.org/TR/mediaqueries-5/</a>
    </dd><dt id="bib-personalization">[personalization]</dt><dd>
      <a href="https://www.w3.org/TR/personalization-semantics-content-1.0/"><cite>Personalization Semantics Content Module 1.0</cite></a>.  W3C. 27 January 2020. URL: <a href="https://www.w3.org/TR/personalization-semantics-content-1.0/">https://www.w3.org/TR/personalization-semantics-content-1.0/</a>
    </dd><dt id="bib-rtt-sip">[rtt-sip]</dt><dd>
      <a href="https://tools.ietf.org/html/rfc5194"><cite>Framework for Real-Time Text over IP Using the Session Initiation Protocol (SIP)</cite></a>.  IETF, Network Working Group. June 2008. URL: <a href="https://tools.ietf.org/html/rfc5194">https://tools.ietf.org/html/rfc5194</a>
    </dd><dt id="bib-rule-types">[rule-types]</dt><dd>
      <a href="https://www.w3.org/TR/act-rules-format/#rule-types"><cite>Accessibility Conformance Testing (ACT) Rules Format 1.0 - W3C Recommendation, 31 October 2019</cite></a>. Wilco Fiers; Maureen Kraft; Mary Jo Mueller ; Shadi Abou-Zahra.  W3C. 2019. URL: <a href="https://www.w3.org/TR/act-rules-format/#rule-types">https://www.w3.org/TR/act-rules-format/#rule-types</a>
    </dd><dt id="bib-total-conversation">[total-conversation]</dt><dd>
      <a href="https://www.itu.int/en/ITU-T/studygroups/com16/accessibility/Pages/conversation.aspx"><cite>ITU-T SG 16 Work on Accessibility - Total Conversation</cite></a>. International Telecommunication Union (ITU). 2020. URL: <a href="https://www.itu.int/en/ITU-T/studygroups/com16/accessibility/Pages/conversation.aspx">https://www.itu.int/en/ITU-T/studygroups/com16/accessibility/Pages/conversation.aspx</a>
    </dd><dt id="bib-webrtc">[webrtc]</dt><dd>
      <a href="https://www.w3.org/TR/webrtc/"><cite>WebRTC 1.0: Real-Time Communication Between Browsers</cite></a>.  W3C. 26 January 2021. URL: <a href="https://www.w3.org/TR/webrtc/">https://www.w3.org/TR/webrtc/</a>
    </dd><dt id="bib-webrtc-priority">[webrtc-priority]</dt><dd>
      <a href="https://w3c.github.io/webrtc-priority/"><cite>WebRTC DSCP Control API</cite></a>.  W3C. 12 February 2020. URL: <a href="https://w3c.github.io/webrtc-priority/">https://w3c.github.io/webrtc-priority/</a>
    </dd><dt id="bib-webrtc-use-cases">[webrtc-use-cases]</dt><dd>
      <a href="https://www.w3.org/TR/webrtc-nv-use-cases/"><cite>WebRTC Next Version Use Cases</cite></a>.  W3C. 11 December 2018. URL: <a href="https://www.w3.org/TR/webrtc-nv-use-cases/">https://www.w3.org/TR/webrtc-nv-use-cases/</a>
    </dd><dt id="bib-xaur">[xaur]</dt><dd>
      <a href="https://www.w3.org/TR/xaur/"><cite>XR Accessibility User Requirements</cite></a>.  W3C. 16 Sept 2020. URL: <a href="https://www.w3.org/TR/xaur/">https://www.w3.org/TR/xaur/</a>
    </dd></dl>
  </section></section><p role="navigation" id="back-to-top">
    <a href="#title"><abbr title="Back to Top">↑</abbr></a>
  </p><script id="respec-dfn-panel">(() => {
// @ts-check
if (document.respec) {
  document.respec.ready.then(setupPanel);
} else {
  setupPanel();
}

function setupPanel() {
  const listener = panelListener();
  document.body.addEventListener("keydown", listener);
  document.body.addEventListener("click", listener);
}

function panelListener() {
  /** @type {HTMLElement} */
  let panel = null;
  return event => {
    const { target, type } = event;

    if (!(target instanceof HTMLElement)) return;

    // For keys, we only care about Enter key to activate the panel
    // otherwise it's activated via a click.
    if (type === "keydown" && event.key !== "Enter") return;

    const action = deriveAction(event);

    switch (action) {
      case "show": {
        hidePanel(panel);
        /** @type {HTMLElement} */
        const dfn = target.closest("dfn, .index-term");
        panel = document.getElementById(`dfn-panel-for-${dfn.id}`);
        const coords = deriveCoordinates(event);
        displayPanel(dfn, panel, coords);
        break;
      }
      case "dock": {
        panel.style.left = null;
        panel.style.top = null;
        panel.classList.add("docked");
        break;
      }
      case "hide": {
        hidePanel(panel);
        panel = null;
        break;
      }
    }
  };
}

/**
 * @param {MouseEvent|KeyboardEvent} event
 */
function deriveCoordinates(event) {
  const target = /** @type HTMLElement */ (event.target);

  // We prevent synthetic AT clicks from putting
  // the dialog in a weird place. The AT events sometimes
  // lack coordinates, so they have clientX/Y = 0
  const rect = target.getBoundingClientRect();
  if (
    event instanceof MouseEvent &&
    event.clientX >= rect.left &&
    event.clientY >= rect.top
  ) {
    // The event probably happened inside the bounding rect...
    return { x: event.clientX, y: event.clientY };
  }

  // Offset to the middle of the element
  const x = rect.x + rect.width / 2;
  // Placed at the bottom of the element
  const y = rect.y + rect.height;
  return { x, y };
}

/**
 * @param {Event} event
 */
function deriveAction(event) {
  const target = /** @type {HTMLElement} */ (event.target);
  const hitALink = !!target.closest("a");
  if (target.closest("dfn:not([data-cite]), .index-term")) {
    return hitALink ? "none" : "show";
  }
  if (target.closest(".dfn-panel")) {
    if (hitALink) {
      return target.classList.contains("self-link") ? "hide" : "dock";
    }
    const panel = target.closest(".dfn-panel");
    return panel.classList.contains("docked") ? "hide" : "none";
  }
  if (document.querySelector(".dfn-panel:not([hidden])")) {
    return "hide";
  }
  return "none";
}

/**
 * @param {HTMLElement} dfn
 * @param {HTMLElement} panel
 * @param {{ x: number, y: number }} clickPosition
 */
function displayPanel(dfn, panel, { x, y }) {
  panel.hidden = false;
  // distance (px) between edge of panel and the pointing triangle (caret)
  const MARGIN = 20;

  const dfnRects = dfn.getClientRects();
  // Find the `top` offset when the `dfn` can be spread across multiple lines
  let closestTop = 0;
  let minDiff = Infinity;
  for (const rect of dfnRects) {
    const { top, bottom } = rect;
    const diffFromClickY = Math.abs((top + bottom) / 2 - y);
    if (diffFromClickY < minDiff) {
      minDiff = diffFromClickY;
      closestTop = top;
    }
  }

  const top = window.scrollY + closestTop + dfnRects[0].height;
  const left = x - MARGIN;
  panel.style.left = `${left}px`;
  panel.style.top = `${top}px`;

  // Find if the panel is flowing out of the window
  const panelRect = panel.getBoundingClientRect();
  const SCREEN_WIDTH = Math.min(window.innerWidth, window.screen.width);
  if (panelRect.right > SCREEN_WIDTH) {
    const newLeft = Math.max(MARGIN, x + MARGIN - panelRect.width);
    const newCaretOffset = left - newLeft;
    panel.style.left = `${newLeft}px`;
    /** @type {HTMLElement} */
    const caret = panel.querySelector(".caret");
    caret.style.left = `${newCaretOffset}px`;
  }

  // As it's a dialog, we trap focus.
  // TODO: when <dialog> becomes a implemented, we should really
  // use that.
  trapFocus(panel, dfn);
}

/**
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function trapFocus(panel, dfn) {
  /** @type NodeListOf<HTMLAnchorElement> elements */
  const anchors = panel.querySelectorAll("a[href]");
  // No need to trap focus
  if (!anchors.length) return;

  // Move focus to first anchor element
  const first = anchors.item(0);
  first.focus();

  const trapListener = createTrapListener(anchors, panel, dfn);
  panel.addEventListener("keydown", trapListener);

  // Hiding the panel releases the trap
  const mo = new MutationObserver(records => {
    const [record] = records;
    const target = /** @type HTMLElement */ (record.target);
    if (target.hidden) {
      panel.removeEventListener("keydown", trapListener);
      mo.disconnect();
    }
  });
  mo.observe(panel, { attributes: true, attributeFilter: ["hidden"] });
}

/**
 *
 * @param {NodeListOf<HTMLAnchorElement>} anchors
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function createTrapListener(anchors, panel, dfn) {
  const lastIndex = anchors.length - 1;
  let currentIndex = 0;
  return event => {
    switch (event.key) {
      // Hitting "Tab" traps us in a nice loop around elements.
      case "Tab": {
        event.preventDefault();
        currentIndex += event.shiftKey ? -1 : +1;
        if (currentIndex < 0) {
          currentIndex = lastIndex;
        } else if (currentIndex > lastIndex) {
          currentIndex = 0;
        }
        anchors.item(currentIndex).focus();
        break;
      }

      // Hitting "Enter" on an anchor releases the trap.
      case "Enter":
        hidePanel(panel);
        break;

      // Hitting "Escape" returns focus to dfn.
      case "Escape":
        hidePanel(panel);
        dfn.focus();
        return;
    }
  };
}

/** @param {HTMLElement} panel */
function hidePanel(panel) {
  if (!panel) return;
  panel.hidden = true;
  panel.classList.remove("docked");
}
})()</script><script src="https://www.w3.org/scripts/TR/2021/fixup.js"></script></body></html>